#!/usr/bin/env python3
"""
Generate shared backend utilities.
This script regenerates the exact shared files found in the working project.
"""

import os
from pathlib import Path

SHARED_FILES = {
    "__init__.py": """\nEmberLearn Shared Backend Utilities\n\nThis module provides common utilities used across all AI agent microservices:\n- Logging configuration with structlog\n- Correlation ID middleware for request tracing\n- Dapr client helpers\n- Pydantic models/schemas\n- Environment configuration\n"""\n\nfrom .config import settings\nfrom .logging_config import setup_logging, get_logger\nfrom .correlation import CorrelationMiddleware, get_correlation_id\nfrom .dapr_client import get_dapr_client\nfrom .models import (\n    BaseResponse,\n    ErrorResponse,\n    ChatMessage,\n    ChatRequest,\n    ChatResponse,\n    CodeExecutionRequest,\n    CodeExecutionResponse,\n    ExerciseRequest,\n    ExerciseResponse,\n    ProgressData,\n    MasteryLevel,\n)\n\n__all__ = [\n    # Config\n    "settings",\n    # Logging\n    "setup_logging",\n    "get_logger",\n    # Correlation\n    "CorrelationMiddleware",\n    "get_correlation_id",\n    # Dapr\n    "get_dapr_client",\n    # Models\n    "BaseResponse",\n    "ErrorResponse",\n    "ChatMessage",\n    "ChatRequest",\n    "ChatResponse",\n    "CodeExecutionRequest",\n    "CodeExecutionResponse",\n    "ExerciseRequest",\n    "ExerciseResponse",\n    "ProgressData",\n    "MasteryLevel",\n]\n",
    "config.py": """\nEnvironment Configuration\n\nCentralized configuration management using Pydantic Settings.\nLoads from environment variables and .env files.\n"""\n\nfrom functools import lru_cache\nfrom typing import Optional\nfrom pydantic_settings import BaseSettings, SettingsConfigDict\n\n\nclass Settings(BaseSettings):\n    """Application settings loaded from environment variables."""\n    \n    model_config = SettingsConfigDict(\n        env_file=".env",\n        env_file_encoding="utf-8",\n        case_sensitive=False,\n        extra="ignore",\n    )\n    \n    # Application\n    app_name: str = "EmberLearn"\n    app_version: str = "1.0.0"\n    environment: str = "development"\n    debug: bool = False\n    \n    # Server\n    host: str = "0.0.0.0"\n    port: int = 8000\n    \n    # OpenAI\n    openai_api_key: Optional[str] = None\n    openai_model: str = "gpt-4o-mini"\n    openai_max_tokens: int = 2048\n    openai_temperature: float = 0.7\n    \n    # Database (Neon PostgreSQL)\n    database_url: Optional[str] = None\n    database_pool_size: int = 5\n    database_max_overflow: int = 10\n    \n    # Dapr\n    dapr_http_port: int = 3500\n    dapr_grpc_port: int = 50001\n    dapr_app_id: str = "emberlearn"\n    dapr_pubsub_name: str = "kafka-pubsub"\n    dapr_statestore_name: str = "postgres-statestore"\n    \n    # Kafka Topics\n    kafka_topic_learning: str = "learning.events"\n    kafka_topic_code: str = "code.events"\n    kafka_topic_exercise: str = "exercise.events"\n    kafka_topic_struggle: str = "struggle.alerts"\n    \n    # Code Sandbox\n    sandbox_timeout_seconds: int = 5\n    sandbox_memory_limit_mb: int = 50\n    sandbox_allowed_imports: str = "math,random,datetime,collections,itertools,functools,string,re,json"\n    \n    # JWT Auth\n    jwt_secret_key: Optional[str] = None\n    jwt_algorithm: str = "RS256"\n    jwt_expiry_hours: int = 24\n    \n    # Logging\n    log_level: str = "INFO"\n    log_format: str = "json"\n    \n    # CORS\n    cors_origins: str = "http://localhost:3000,http://localhost:8080"\n    \n    @property\n    def cors_origins_list(self) -> list[str]:\n        """Parse CORS origins string into list."""\n        return [origin.strip() for origin in self.cors_origins.split(",")]\n    \n    @property\n    def sandbox_allowed_imports_list(self) -> list[str]:\n        """Parse allowed imports string into list."""\n        return [imp.strip() for imp in self.sandbox_allowed_imports.split(",")]\n    \n    @property\n    def is_production(self) -> bool:\n        """Check if running in production environment."""\n        return self.environment.lower() == "production"\n    \n    @property\n    def dapr_http_url(self) -> str:\n        """Get Dapr HTTP endpoint URL."""\n        return f"http://localhost:{self.dapr_http_port}"\n\n\n@lru_cache()\ndef get_settings() -> Settings:\n    """Get cached settings instance."""\n    return Settings()\n\n\n# Global settings instance\nsettings = get_settings()\n",
    "correlation.py": """\nCorrelation ID Middleware\n\nProvides request tracing across microservices using correlation IDs.\nIntegrates with structlog for automatic correlation ID logging.\n"""\n\nimport uuid\nfrom contextvars import ContextVar\nfrom typing import Callable, Optional\n\nfrom fastapi import Request, Response\nfrom starlette.middleware.base import BaseHTTPMiddleware\nfrom starlette.types import ASGIApp\n
import structlog\n\n# Context variable for correlation ID\ncorrelation_id_ctx: ContextVar[Optional[str]] = ContextVar(\n    "correlation_id", default=None\n)\n\n# Header names for correlation ID propagation\nCORRELATION_ID_HEADER = "X-Correlation-ID"\nREQUEST_ID_HEADER = "X-Request-ID"\n\n\ndef get_correlation_id() -> Optional[str]:\n    """Get the current correlation ID from context."""\n    return correlation_id_ctx.get()\n\n\ndef set_correlation_id(correlation_id: str) -> None:\n    """Set the correlation ID in context."""\n    correlation_id_ctx.set(correlation_id)\n\n\ndef generate_correlation_id() -> str:\n    """Generate a new correlation ID."""\n    return str(uuid.uuid4())\n\n\nclass CorrelationMiddleware(BaseHTTPMiddleware):\n    """\n    Middleware that manages correlation IDs for request tracing.  \n    \n    - Extracts correlation ID from incoming request headers\n    - Generates new ID if not present\n    - Adds correlation ID to response headers\n    - Binds correlation ID to structlog context\n    """\n    \n    def __init__(\n        self,\n        app: ASGIApp,\n        header_name: str = CORRELATION_ID_HEADER,\n    ) -> None:\n        super().__init__(app)\n        self.header_name = header_name\n    \n    async def dispatch(\n        self,\n        request: Request,\n        call_next: Callable,\n    ) -> Response:\n        # Extract or generate correlation ID\n        correlation_id = (\n            request.headers.get(self.header_name)\n            or request.headers.get(REQUEST_ID_HEADER)\n            or generate_correlation_id()\n        )\n        \n        # Set in context\n        set_correlation_id(correlation_id)\n        \n        # Bind to structlog\n        structlog.contextvars.bind_contextvars(correlation_id=correlation_id)\n        \n        # Process request\n        response = await call_next(request)\n        \n        # Add to response headers\n        response.headers[self.header_name] = correlation_id\n        \n        return response\n\n\ndef get_correlation_headers() -> dict[str, str]:\n    """Get correlation ID as request headers for service invocation."""\n    cid = get_correlation_id()\n    return {CORRELATION_ID_HEADER: cid} if cid else {}\n",
    "dapr_client.py": """\nDapr Client Helper Functions\n\nProvides a simplified interface for Dapr operations:\n- State management (get/set/delete)\n- Pub/Sub messaging\n- Service invocation\n"""\n\nimport json\nfrom typing import Any, Optional\n
import httpx\n
from .config import settings\nfrom .correlation import get_correlation_headers\nfrom .logging_config import get_logger\n
logger = get_logger(__name__)\n

class DaprClient:\n    """\n    Helper class for Dapr sidecar operations.  \n    \n    Uses HTTP API for simplicity and compatibility.\n    """\n    \n    def __init__(\n        self,\n        dapr_http_port: Optional[int] = None,\n        pubsub_name: Optional[str] = None,\n        statestore_name: Optional[str] = None,\n    ):\n        self.dapr_port = dapr_http_port or settings.dapr_http_port\n        self.base_url = f"http://localhost:{self.dapr_port}"\n        self.pubsub_name = pubsub_name or settings.dapr_pubsub_name\n        self.statestore_name = statestore_name or settings.dapr_statestore_name\n        self._client: Optional[httpx.AsyncClient] = None\n    \n    async def _get_client(self) -> httpx.AsyncClient:\n        """Get or create HTTP client."""\n        if self._client is None or self._client.is_closed:\n            self._client = httpx.AsyncClient(\n                base_url=self.base_url,\n                timeout=30.0,\n            )\n        return self._client\n    \n    async def close(self) -> None:\n        """Close the HTTP client."""\n        if self._client and not self._client.is_closed:\n            await self._client.aclose()\n    \n    # ==================== State Management ====================\n    \n    async def get_state(\n        self,\n        key: str,\n        store_name: Optional[str] = None,\n    ) -> Optional[Any]:\n        """\n        Get state value by key.\n        \n        Args:\n            key: State key\n            store_name: Override default state store name\n        """\n        store = store_name or self.statestore_name\n        client = await self._get_client()\n        \n        try:\n            response = await client.get(f"/v1.0/state/{store}/{key}")\n            \n            if response.status_code == 204 or not response.text:\n                return None\n            \n            if response.status_code == 200:\n                return response.json()\n            \n            logger.error("failed_to_get_state", key=key, status=response.status_code)\n            return None\n            \n        except Exception as e:\n            logger.error("dapr_state_error", key=key, error=str(e))\n            return None\n            \n    async def save_state(\n        self,\n        key: str,\n        value: Any,\n        store_name: Optional[str] = None,\n    ) -> bool:\n        """\n        Save state value.\n        """\n        store = store_name or self.statestore_name\n        client = await self._get_client()\n        \n        data = [{"key": key, "value": value}]\n        \n        try:\n            response = await client.post(\n                f"/v1.0/state/{store}",\n                json=data,\n            )\n            return response.status_code == 204\n            \n        except Exception as e:\n            logger.error("dapr_save_state_error", key=key, error=str(e))\n            return False\n\n    # ==================== Pub/Sub ====================\n    \n    async def publish_event(\n        self,\n        topic: str,\n        data: Any,\n        pubsub_name: Optional[str] = None,\n    ) -> bool:\n        """\n        Publish an event to a topic.\n        """\n        pubsub = pubsub_name or self.pubsub_name\n        client = await self._get_client()\n        \n        try:\n            response = await client.post(\n                f"/v1.0/publish/{pubsub}/{topic}",\n                json=data,\n                headers=get_correlation_headers(),\n            )\n            return response.status_code == 204\n            \n        except Exception as e:\n            logger.error("dapr_publish_error", topic=topic, error=str(e))\n            return False\n\n    # ==================== Service Invocation ====================\n    \n    async def invoke_service(\n        self,\n        app_id: str,\n        method: str,\n        data: Optional[Any] = None,\n        http_method: str = "POST",\n    ) -> Any:\n        """\n        Invoke a method on another service.\n        """\n        client = await self._get_client()\n        \n        try:\n            response = await client.request(\n                method=http_method,\n                url=f"/v1.0/invoke/{app_id}/method/{method}",\n                json=data,\n                headers=get_correlation_headers(),\n            )\n            \n            if response.status_code >= 200 and response.status_code < 300:\n                return response.json() if response.text else None\n                \n            logger.error("service_invocation_failed", app_id=app_id, method=method, status=response.status_code)\n            raise Exception(f"Service invocation failed with status {response.status_code}")\n            \n        except Exception as e:\n            logger.error("dapr_invoke_error", app_id=app_id, method=method, error=str(e))\n            raise\n\n    async def health_check(self) -> bool:\n        """Check Dapr sidecar health."""\n        client = await self._get_client()\n        try:\n            response = await client.get("/v1.0/healthz")\n            return response.status_code == 204\n        except Exception:\n            return False\n\n\n# Singleton instance helper\n_dapr_client: Optional[DaprClient] = None\n\ndef get_dapr_client() -> DaprClient:\n    """Get or create global Dapr client instance."""\n    global _dapr_client\n    if _dapr_client is None:\n        _dapr_client = DaprClient()\n    return _dapr_client\n",
    "logging_config.py": """\nStructured Logging Configuration\n\nUses structlog for JSON-formatted logging with correlation ID support.\nProvides consistent logging across all microservices.\n"""\n\nimport logging\nimport sys\nfrom typing import Any, Optional\n
import structlog\nfrom structlog.types import Processor\n
from .config import settings\n

\ndef add_app_context(\n    logger: logging.Logger,\n    method_name: str,\n    event_dict: dict[str, Any],\n) -> dict[str, Any]:\n    """Add application context to log entries."""\n    event_dict["app"] = settings.app_name\n    event_dict["version"] = settings.app_version\n    event_dict["environment"] = settings.environment\n    return event_dict\n\n\ndef setup_logging(\n    service_name: Optional[str] = None,\n    log_level: Optional[str] = None,\n) -> None:\n    """\n    Configure structured logging for the application.  \n    \n    Args:\n        service_name: Name of the service (for log context)\n        log_level: Override log level from settings\n    """\n    level = log_level or settings.log_level\n    \n    # Configure standard library logging\n    logging.basicConfig(\n        format="%(message)s",\n        stream=sys.stdout,\n        level=getattr(logging, level.upper()),\n    )\n    \n    # Shared processors for all outputs\n    shared_processors: list[Processor] = [\n        structlog.contextvars.merge_contextvars,\n        structlog.stdlib.add_log_level,\n        structlog.stdlib.add_logger_name,\n        structlog.stdlib.PositionalArgumentsFormatter(),\n        structlog.processors.TimeStamper(fmt="iso"),\n        structlog.processors.StackInfoRenderer(),\n        structlog.processors.UnicodeDecoder(),\n        add_app_context,\n    ]\n    \n    # Add service name if provided\n    if service_name:\n        def add_service_name(\n            logger: logging.Logger,\n            method_name: str,\n            event_dict: dict[str, Any],\n        ) -> dict[str, Any]:\n            event_dict["service"] = service_name\n            return event_dict\n        shared_processors.append(add_service_name)\n    \n    # Choose renderer based on format setting\n    if settings.log_format == "json":\n        renderer = structlog.processors.JSONRenderer()\n    else:\n        renderer = structlog.dev.ConsoleRenderer(colors=True)\n    \n    structlog.configure(\n        processors=shared_processors + [\n            structlog.stdlib.ProcessorFormatter.wrap_for_formatter,\n        ],\n        logger_factory=structlog.stdlib.LoggerFactory(),\n        wrapper_class=structlog.stdlib.BoundLogger,\n        cache_logger_on_first_use=True,\n    )\n    \n    # Configure formatter for stdlib handlers\n    formatter = structlog.stdlib.ProcessorFormatter(\n        foreign_pre_chain=shared_processors,\n        processors=[
            structlog.stdlib.ProcessorFormatter.remove_processors_meta,\n            renderer,\n        ],\n    )\n    \n    # Apply formatter to root logger handlers\n    root_logger = logging.getLogger()\n    for handler in root_logger.handlers:\n        handler.setFormatter(formatter)\n\n\ndef get_logger(name: Optional[str] = None) -> structlog.stdlib.BoundLogger:\n    """Get a structured logger instance."""\n    return structlog.get_logger(name)\n\n\n# Convenience function for binding context\ndef bind_context(**kwargs: Any) -> None:\n    """Bind context variables to all subsequent log calls in this context."""\n    structlog.contextvars.bind_contextvars(**kwargs)\n\n\ndef clear_context() -> None:\n    """Clear all bound context variables."""\n    structlog.contextvars.clear_contextvars()\n",
    "models.py": """\nPydantic Models and Schemas\n\nShared data models used across all AI agent microservices.\n"""\n\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Optional\n
from pydantic import BaseModel, Field\n
\n# ==================== Enums ====================\n\nclass MasteryLevel(str, Enum):\n    """Student mastery level for a topic."""\n    BEGINNER = "beginner"      # 0-40%\n    LEARNING = "learning"      # 41-70%\n    PROFICIENT = "proficient"  # 71-90%\n    MASTERED = "mastered"      # 91-100%\n    \n    @classmethod\n    def from_score(cls, score: float) -> "MasteryLevel":\n        """Get mastery level from percentage score."""\n        if score <= 40:\n            return cls.BEGINNER\n        elif score <= 70:\n            return cls.LEARNING\n        elif score <= 90:\n            return cls.PROFICIENT\n        return cls.MASTERED\n\n\nclass AgentType(str, Enum):\n    """Types of AI agents in the system."""\n    TRIAGE = "triage"\n    CONCEPTS = "concepts"\n    CODE_REVIEW = "code_review"\n    DEBUG = "debug"\n    EXERCISE = "exercise"\n    PROGRESS = "progress"\n\n\nclass Difficulty(str, Enum):\n    """Exercise difficulty levels."""\n    EASY = "easy"\n    MEDIUM = "medium"\n    HARD = "hard"\n\n\nclass MessageRole(str, Enum):\n    """Chat message roles."""\n    USER = "user"\n    ASSISTANT = "assistant"\n    SYSTEM = "system"\n\n\n# ==================== Base Models ====================\n\nclass BaseResponse(BaseModel):\n    """Base response model with common fields."""\n    success: bool = True\n    message: Optional[str] = None\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n\n\nclass ErrorResponse(BaseModel):\n    """Error response model."""\n    success: bool = False\n    error: str\n    error_code: Optional[str] = None\n    details: Optional[dict[str, Any]] = None\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n\n\n# ==================== Chat Models ====================\n\nclass ChatMessage(BaseModel):\n    """A single chat message."""\n    role: MessageRole\n    content: str\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n    agent_type: Optional[AgentType] = None\n    metadata: Optional[dict[str, Any]] = None\n\n\nclass ChatRequest(BaseModel):\n    """Request to chat with an AI agent."""\n    message: str = Field(..., min_length=1, max_length=10000)\n    user_id: str\n    session_id: Optional[str] = None\n    context: Optional[dict[str, Any]] = None\n    history: list[ChatMessage] = Field(default_factory=list)\n    target_agent: Optional[AgentType] = None\n\n\nclass ChatResponse(BaseResponse):\n    """Response from an AI agent chat."""\n    response: str\n    agent_type: AgentType\n    session_id: str\n    suggestions: list[str] = Field(default_factory=list)\n    related_topics: list[str] = Field(default_factory=list)\n    code_examples: list[str] = Field(default_factory=list)\n\n\n# ==================== Code Execution Models ====================\n\nclass CodeExecutionRequest(BaseModel):\n    """Request to execute Python code in sandbox."""\n    code: str = Field(..., min_length=1, max_length=50000)\n    user_id: str\n    exercise_id: Optional[str] = None\n    test_cases: list[dict[str, Any]] = Field(default_factory=list)\n    timeout_seconds: int = Field(default=5, ge=1, le=30)\n\n\nclass TestCaseResult(BaseModel):\n    """Result of a single test case execution."""\n    name: str\n    passed: bool\n    input: str\n    expected_output: str\n    actual_output: Optional[str] = None\n    error: Optional[str] = None\n    execution_time_ms: Optional[int] = None\n\n\nclass CodeExecutionResponse(BaseResponse):\n    """Response from code execution."""\n    output: Optional[str] = None\n    error: Optional[str] = None\n    execution_time_ms: int\n    memory_used_mb: Optional[float] = None\n    test_results: list[TestCaseResult] = Field(default_factory=list)\n    passed_count: int = 0\n    total_count: int = 0\n    score: Optional[float] = None\n\n\n# ==================== Exercise Models ====================\n\nclass TestCase(BaseModel):\n    """A test case for an exercise."""\n    id: str\n    name: str\n    input: str\n    expected_output: str\n    hidden: bool = False\n\n\nclass ExerciseRequest(BaseModel):\n    """Request to generate or get an exercise."""\n    topic: str\n    difficulty: Difficulty = Difficulty.MEDIUM\n    user_id: str\n    mastery_score: Optional[float] = None\n    previous_exercises: list[str] = Field(default_factory=list)\n\n\nclass Exercise(BaseModel):\n    """An exercise/challenge."""\n    id: str\n    title: str\n    description: str\n    instructions: str\n    starter_code: str\n    topic: str\n    difficulty: Difficulty\n    estimated_time_minutes: int\n    hints: list[str] = Field(default_factory=list)\n    test_cases: list[TestCase] = Field(default_factory=list)\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n\n\nclass ExerciseResponse(BaseResponse):\n    """Response containing an exercise."""\n    exercise: Exercise\n\n\nclass ExerciseSubmission(BaseModel):\n    """A student's submission for an exercise."""\n    id: str\n    user_id: str\n    exercise_id: str\n    code: str\n    score: float\n    passed: bool\n    test_results: list[TestCaseResult]\n    feedback: Optional[str] = None\n    submitted_at: datetime = Field(default_factory=datetime.utcnow)\n\n\n# ==================== Progress Models ====================\n\nclass TopicProgress(BaseModel):\n    """Progress for a single topic."""\n    topic_id: str\n    topic_name: str\n    mastery_score: float = Field(ge=0, le=100)\n    mastery_level: MasteryLevel\n    exercises_completed: int = 0\n    exercises_total: int = 0\n    quiz_average: Optional[float] = None\n    code_quality_average: Optional[float] = None\n    last_activity: Optional[datetime] = None\n\n\nclass ProgressData(BaseModel):\n    """Complete progress data for a student."""\n    user_id: str\n    overall_mastery: float = Field(ge=0, le=100)\n    overall_level: MasteryLevel\n    streak_days: int = 0\n    total_xp: int = 0\n    level: int = 1\n    topics: list[TopicProgress] = Field(default_factory=list)\n    recent_exercises: list[str] = Field(default_factory=list)\n    achievements: list[str] = Field(default_factory=list)\n    updated_at: datetime = Field(default_factory=datetime.utcnow)\n\n\nclass ProgressUpdateRequest(BaseModel):\n    """Request to update student progress."""\n    user_id: str\n    topic_id: str\n    exercise_score: Optional[float] = None\n    quiz_score: Optional[float] = None\n    code_quality_score: Optional[float] = None\n\n\n# ==================== Struggle Detection Models ====================\n\nclass StruggleTrigger(str, Enum):\n    """Types of struggle triggers."""\n    REPEATED_ERROR = "repeated_error"        # Same error 3+ times\n    STUCK_TOO_LONG = "stuck_too_long"        # >10 min on exercise\n    LOW_QUIZ_SCORE = "low_quiz_score"        # <50% quiz score\n    EXPLICIT_STATEMENT = "explicit_statement" # "I don't understand"\n    FAILED_EXECUTIONS = "failed_executions"  # 5+ failed runs\n\n\nclass StruggleAlert(BaseModel):\n    """Alert when a student is struggling."""\n    id: str\n    user_id: str\n    trigger: StruggleTrigger\n    topic: str\n    exercise_id: Optional[str] = None\n    details: dict[str, Any] = Field(default_factory=dict)\n    severity: int = Field(ge=1, le=5, default=3)\n    created_at: datetime = Field(default_factory=datetime.utcnow)\n    resolved: bool = False\n    resolved_at: Optional[datetime] = None\n\n\n# ==================== Event Models ====================\n\nclass LearningEvent(BaseModel):\n    """Event published when learning activity occurs."""\n    event_type: str\n    user_id: str\n    topic: Optional[str] = None\n    exercise_id: Optional[str] = None\n    data: dict[str, Any] = Field(default_factory=dict)\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n\n\nclass CodeEvent(BaseModel):\n    """Event published when code is executed."""\n    user_id: str\n    exercise_id: Optional[str] = None\n    success: bool\n    error_type: Optional[str] = None\n    execution_time_ms: int\n    timestamp: datetime = Field(default_factory=datetime.utcnow)\n",
    "fallback.py": """\nOpenAI API Fallback - Graceful Degradation\n\nProvides fallback responses when OpenAI API is unavailable:\n1. Cached response retrieval\n2. Predefined answer lookup\n3. Graceful degradation messaging\n"""\n\nimport hashlib\nimport json\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Any\nfrom collections import OrderedDict\n
from .config import settings\nfrom .logging_config import get_logger\nfrom .models import AgentType\n
logger = get_logger(__name__)\n
# Cache settings\nCACHE_MAX_SIZE = 1000\nCACHE_TTL_HOURS = 24\n

class ResponseCache:\n    """LRU cache for API responses."""\n    \n    def __init__(self, max_size: int = CACHE_MAX_SIZE):\n        self.max_size = max_size\n        self._cache: OrderedDict[str, dict] = OrderedDict()\n    \n    def _make_key(self, agent_type: str, query: str) -> str:\n        """Create cache key from agent type and query."""\n        normalized = query.lower().strip()\n        content = f"{agent_type}:{normalized}"\n        return hashlib.md5(content.encode()).hexdigest()\n    \n    def get(self, agent_type: str, query: str) -> Optional[str]:\n        """Get cached response if available and not expired."""\n        key = self._make_key(agent_type, query)\n        \n        if key not in self._cache:\n            return None\n        \n        entry = self._cache[key]\n        \n        # Check expiration\n        if datetime.utcnow() > entry["expires_at"]:\n            del self._cache[key]\n            return None\n        \n        # Move to end (LRU)\n        self._cache.move_to_end(key)\n        \n        logger.debug("cache_hit", agent_type=agent_type)\n        return entry["response"]\n    \n    def set(self, agent_type: str, query: str, response: str, ttl_hours: int = CACHE_TTL_HOURS):\n        """Cache a response."""\n        key = self._make_key(agent_type, query)\n        \n        # Evict oldest if at capacity\n        while len(self._cache) >= self.max_size:\n            self._cache.popitem(last=False)\n        \n        self._cache[key] = {\n            "response": response,\n            "expires_at": datetime.utcnow() + timedelta(hours=ttl_hours),\n            "created_at": datetime.utcnow(),\n        }\n    \n    def clear(self):\n        """Clear all cached responses."""\n        self._cache.clear()\n\n\n# Predefined responses for common queries\nPREDEFINED_RESPONSES = {\n    AgentType.CONCEPTS: {\n        "what is a variable": (\n            "A **variable** in Python is like a labeled container that stores data. "\n            "You create one by choosing a name and using the `=` sign:\n\n"\n            "```python\n"\n            "name = 'Alice'  # String variable\n"\n            "age = 25        # Integer variable\n"\n            "price = 19.99   # Float variable\n"\n            "```\n\n"\n            "Variables can be changed (they're 'variable'!) and Python automatically "\n            "figures out what type of data you're storing."
        ),\n        "what is a loop": (\n            "A **loop** lets you repeat code multiple times. Python has two main types:\n\n"\n            "**For Loop** - when you know how many times:\n"\n            "```python\n"\n            "for i in range(5):\n"\n            "    print(i)  # Prints 0, 1, 2, 3, 4\n"\n            "```\n\n"\n            "**While Loop** - when you have a condition:\n"\n            "```python\n"\n            "count = 0\n"\n            "while count < 5:\n"\n            "    print(count)\n"\n            "    count += 1\n"\n            "```"
        ),\n        "what is a function": (\n            "A **function** is a reusable block of code that performs a specific task. "\n            "You define it once and can call it many times:\n\n"\n            "```python\n"\n            "def greet(name):\n"\n            "    return f'Hello, {name}!'\n\n"\n            "# Call the function\n"\n            "message = greet('Alice')\n"\n            "print(message)  # Hello, Alice!\n"\n            "```\n\n"\n            "Functions help organize code and avoid repetition."
        ),\n        "what is a list": (\n            "A **list** is an ordered collection that can hold multiple items:\n\n"\n            "```python\n"\n            "fruits = ['apple', 'banana', 'cherry']\n\n"\n            "# Access by index (starts at 0)\n"\n            "print(fruits[0])  # apple\n\n"\n            "# Add items\n"\n            "fruits.append('date')\n\n"\n            "# Loop through\n"\n            "for fruit in fruits:\n"\n            "    print(fruit)\n"\n            "```\n\n"\n            "Lists are mutable - you can change them after creation."
        ),\n        "what is a dictionary": (\n            "A **dictionary** stores key-value pairs, like a real dictionary:\n\n"\n            "```python\n"\n            "student = {\n"\n            "    'name': 'Alice',\n"\n            "    'age': 20,\n"\n            "    'grade': 'A'\n"\n            "}\n\n"\n            "# Access by key\n"\n            "print(student['name'])  # Alice\n\n"\n            "# Add/update\n"\n            "student['email'] = 'alice@example.com'\n"\n            "```\n\n"\n            "Use dictionaries when you need to look up values by a unique key."
        ),\n        "what is a class": (\n            "A **class** is a blueprint for creating objects. It bundles data and functions together:\n\n"\n            "```python\n"\n            "class Dog:\n"\n            "    def __init__(self, name):\n"\n            "        self.name = name\n"\n            "    \n"\n            "    def bark(self):\n"\n            "        return f'{self.name} says woof!'\n\n"\n            "# Create an object\n"\n            "my_dog = Dog('Buddy')\n"\n            "print(my_dog.bark())  # Buddy says woof!\n"\n            "```\n\n"\n            "Classes are the foundation of Object-Oriented Programming (OOP)."
        ),\n    },\n    AgentType.DEBUG: {\n        "nameerror": (\n            "**NameError** means Python can't find a variable or function you're trying to use.\n\n"\n            "**Common causes:**\n"\n            "1. Typo in the variable name\n"\n            "2. Using a variable before defining it\n"\n            "3. Variable defined in a different scope\n\n"\n            "**Fix:** Check spelling and make sure you've defined the variable before using it."
        ),\n        "typeerror": (\n            "**TypeError** means you're using the wrong type of data for an operation.\n\n"\n            "**Common causes:**\n"\n            "1. Adding a string to a number: `'5' + 5`\n"\n            "2. Calling something that isn't a function\n"\n            "3. Wrong number of arguments to a function\n\n"\n            "**Fix:** Check your data types with `type()` and convert if needed."
        ),\n        "indexerror": (\n            "**IndexError** means you're trying to access a list position that doesn't exist.\n\n"\n            "**Common causes:**\n"\n            "1. List is empty but you're accessing `list[0]`\n"\n            "2. Off-by-one error (remember: indices start at 0!)\n"\n            "3. Loop going past the end of the list\n\n"\n            "**Fix:** Check list length with `len()` before accessing."
        ),\n        "syntaxerror": (\n            "**SyntaxError** means Python can't understand your code's structure.\n\n"\n            "**Common causes:**\n"\n            "1. Missing colon after `if`, `for`, `def`, `class`\n"\n            "2. Unmatched parentheses or brackets\n"\n            "3. Missing quotes around strings\n\n"\n            "**Fix:** Check the line number in the error and look for typos."
        ),\n        "keyerror": (\n            "**KeyError** means you're trying to access a dictionary key that doesn't exist.\n\n"\n            "**Common causes:**\n"\n            "1. Typo in the key name\n"\n            "2. Key hasn't been added yet\n"\n            "3. Case sensitivity (`'Name'` vs `'name'`)\n\n"\n            "**Fix:** Use `.get()` method or check with `if key in dict`."
        ),\n    },\n    AgentType.CODE_REVIEW: {\n        "default": (\n            "Here are some general Python best practices:\n\n"\n            "1. **Use meaningful variable names** - `user_count` not `x`\n"\n            "2. **Follow PEP 8** - 4 spaces for indentation, max 79 chars per line\n"\n            "3. **Add docstrings** - Explain what functions do\n"\n            "4. **Handle errors** - Use try/except for risky operations\n"\n            "5. **Keep functions small** - Each should do one thing well\n\n"\n            "Would you like me to review specific code?"
        ),\n    },\n    AgentType.TRIAGE: {\n        "default": (\n            "I can help you with:\n\n"\n            "- **Learning concepts** - Ask me to explain any Python topic\n"\n            "- **Debugging** - Share your error and I'll help fix it\n"\n            "- **Code review** - Paste your code for feedback\n"\n            "- **Practice** - Request exercises to test your skills\n"\n            "- **Progress** - Check how you're doing\n\n"\n            "What would you like help with?"
        ),\n    },\n}\n
# Graceful degradation messages\nDEGRADATION_MESSAGES = {\n    AgentType.CONCEPTS: (\n        "I'm having trouble connecting to my knowledge base right now. "\n        "Here's what I can tell you from my basic knowledge:\n\n"\n        "{fallback_content}\n\n"\n        "_For more detailed explanations, please try again in a few minutes._"\n    ),\n    AgentType.DEBUG: (\n        "I'm experiencing some technical difficulties, but I can still help!\n\n"\n        "{fallback_content}\n\n"\n        "_For more specific debugging help, please try again shortly._"\n    ),\n    AgentType.CODE_REVIEW: (\n        "My detailed analysis is temporarily unavailable. "\n        "Here's a basic review:\n\n"\n        "{fallback_content}\n\n"\n        "_For comprehensive feedback, please try again in a few minutes._"\n    ),\n    AgentType.EXERCISE: (\n        "I'm having trouble generating a custom exercise right now. "\n        "Here's a practice problem you can try:\n\n"\n        "{fallback_content}\n\n"\n        "_For personalized exercises, please try again shortly._"\n    ),\n    AgentType.PROGRESS: (\n        "I couldn't fetch your complete progress data. "\n        "Here's what I have:\n\n"\n        "{fallback_content}\n\n"\n        "_For full progress details, please try again in a few minutes._"\n    ),\n    AgentType.TRIAGE: (\n        "I'm experiencing some connectivity issues. "\n        "Let me help you with what I can:\n\n"\n        "{fallback_content}"\n    ),\n}\n\n\nclass FallbackHandler:\n    """Handles fallback responses when OpenAI API is unavailable."""\n    \n    def __init__(self):\n        self.cache = ResponseCache()\n        self._api_status: dict[str, bool] = {}\n        self._last_check: dict[str, datetime] = {}\n    \n    def get_fallback_response(\n        self,\n        agent_type: AgentType,\n        query: str,\n        context: Optional[dict] = None,\n    ) -> str:\n        """\n        Get a fallback response for a query.\n        \n        Priority:\n        1. Cached response (if available)\n        2. Predefined response (if query matches)\n        3. Generic degradation message\n        """\n        # Try cache first\n        cached = self.cache.get(agent_type.value, query)\n        if cached:\n            return cached\n        \n        # Try predefined responses\n        predefined = self._get_predefined_response(agent_type, query)\n        if predefined:\n            return self._wrap_with_degradation(agent_type, predefined)\n        \n        # Return generic fallback\n        return self._get_generic_fallback(agent_type, context)\n    \n    def cache_response(self, agent_type: AgentType, query: str, response: str):\n        """Cache a successful API response for future fallback."""\n        self.cache.set(agent_type.value, query, response)\n    \n    def mark_api_status(self, agent_type: AgentType, is_available: bool):\n        """Track API availability status."""\n        self._api_status[agent_type.value] = is_available\n        self._last_check[agent_type.value] = datetime.utcnow()\n    \n    def is_api_available(self, agent_type: AgentType) -> bool:\n        """Check if API is currently available."""\n        return self._api_status.get(agent_type.value, True)\n    \n    def _get_predefined_response(self, agent_type: AgentType, query: str) -> Optional[str]:\n        """Look up predefined response for common queries."""\n        responses = PREDEFINED_RESPONSES.get(agent_type, { })\n        \n        # Normalize query\n        query_lower = query.lower().strip()\n        \n        # Direct match\n        if query_lower in responses:\n            return responses[query_lower]\n        \n        # Partial match\n        for key, response in responses.items():\n            if key in query_lower or query_lower in key:\n                return response\n        \n        # Default response for agent type\n        if "default" in responses:\n            return responses["default"]\n        \n        return None\n    \n    def _wrap_with_degradation(self, agent_type: AgentType, content: str) -> str:\n        """Wrap content with degradation message."""\n        template = DEGRADATION_MESSAGES.get(\n            agent_type,\n            "Here's what I can help with:\n\n{fallback_content}"\n        )\n        return template.format(fallback_content=content)\n    \n    def _get_generic_fallback(self, agent_type: AgentType, context: Optional[dict]) -> str:\n        """Get generic fallback when no specific response available."""\n        fallbacks = {\n            AgentType.CONCEPTS: (\n                "I'd love to explain that concept, but I'm having technical difficulties. "\n                "Try asking about: variables, loops, functions, lists, dictionaries, or classes."
            ),\n            AgentType.DEBUG: (\n                "I can help debug your code! Please share:\n"\n                "1. Your code\n"\n                "2. The error message\n\n"\n                "Common errors I can help with: NameError, TypeError, IndexError, SyntaxError, KeyError."
            ),\n            AgentType.CODE_REVIEW: (\n                "I'd be happy to review your code! Please paste it and I'll provide feedback on:\n"\n                "- Code style (PEP 8)\n"\n                "- Efficiency\n"\n                "- Readability\n"\n                "- Best practices"
            ),\n            AgentType.EXERCISE: (\n                "Here's a quick exercise:\n\n"\n                "**Sum of Numbers**\n"\n                "Write a function that takes a list of numbers and returns their sum.\n\n"\n                "```python\n"\n                "def sum_numbers(numbers):\n"\n                "    # Your code here\n"\n                "    pass\n"\n                "```\n\n"\n                "Test: `sum_numbers([1, 2, 3, 4, 5])` should return `15`"
            ),\n            AgentType.PROGRESS: (\n                "I couldn't load your full progress. Keep practicing and check back soon!\n\n"\n                "**Quick Tips:**\n"\n                "- Complete exercises daily to build your streak\n"\n                "- Review topics where you scored below 70%\n"\n                "- Ask for help when stuck - that's how you learn!"
            ),\n            AgentType.TRIAGE: PREDEFINED_RESPONSES[AgentType.TRIAGE]["default"],
        }\n        \n        return fallbacks.get(agent_type, "I'm temporarily unavailable. Please try again shortly.")\n\n\n# Global instance\n_fallback_handler: Optional[FallbackHandler] = None\n\n\ndef get_fallback_handler() -> FallbackHandler:\n    """Get or create the global fallback handler instance."""\n    global _fallback_handler\n    if _fallback_handler is None:\n        _fallback_handler = FallbackHandler()\n    return _fallback_handler\n",
    "struggle_detector.py": """\nStruggle Detection - Identifies When Students Need Help\n\nDetects struggle triggers:\n1. Same error 3+ times (REPEATED_ERROR)\n2. Stuck >10 minutes on exercise (STUCK_TOO_LONG)\n3. Quiz score <50% (LOW_QUIZ_SCORE)\n4. Explicit statements like \"I don't understand\" (EXPLICIT_STATEMENT)\n5. 5+ failed code executions in a row (FAILED_EXECUTIONS)\n\nPublishes alerts to Kafka within 30 seconds of detection.\n"""\n\nimport re\nfrom datetime import datetime, timedelta\nfrom typing import Optional\nfrom uuid import uuid4\nfrom collections import defaultdict\n
from .config import settings\nfrom .logging_config import get_logger\nfrom .models import StruggleAlert, StruggleTrigger\nfrom .dapr_client import get_dapr_client\n
logger = get_logger(__name__)\n
# Detection thresholds\nREPEATED_ERROR_THRESHOLD = 3\nSTUCK_TIME_MINUTES = 10\nLOW_QUIZ_THRESHOLD = 50\nFAILED_EXECUTION_THRESHOLD = 5\n
# Explicit struggle phrases\nSTRUGGLE_PHRASES = [\n    "i don't understand",\n    "i dont understand",\n    "i'm stuck",\n    "im stuck",\n    "i am stuck",\n    "help me",\n    "confused",\n    "i'm lost",\n    "im lost",\n    "i am lost",\n    "this is hard",\n    "too difficult",\n    "can't figure",\n    "cant figure",\n    "don't get it",\n    "dont get it",\n    "makes no sense",\n    "what am i doing wrong",\n    "why doesn't this work",\n    "why doesnt this work",\n    "frustrated",\n    "give up",\n]\n


class StruggleDetector:\n    """Detects when students are struggling and publishes alerts."""\n    \n    def __init__(self):\n        self.dapr = get_dapr_client()\n        \n        # In-memory tracking (would use Redis/Dapr state in production)\n        self._error_history: dict[str, list[dict]] = defaultdict(list)\n        self._exercise_start_times: dict[str, datetime] = {}\n        self._execution_failures: dict[str, int] = defaultdict(int)\n        self._recent_alerts: dict[str, datetime] = {}\n    \n    async def check_error(\n        self,\n        user_id: str,\n        error_type: str,\n        topic: str,\n        exercise_id: Optional[str] = None,\n    ) -> Optional[StruggleAlert]:\n        """\n        Check for repeated error pattern.\n        \n        Triggers if same error type occurs 3+ times.\n        """\n        # Add to error history\n        self._error_history[user_id].append({\n            "error_type": error_type,\n            "timestamp": datetime.utcnow(),\n            "topic": topic,\n            "exercise_id": exercise_id,\n        })\n        \n        # Keep only last 10 errors\n        self._error_history[user_id] = self._error_history[user_id][-10:]\n        \n        # Count recent occurrences of this error type (last 30 minutes)\n        cutoff = datetime.utcnow() - timedelta(minutes=30)\n        recent_same_errors = [\n            e for e in self._error_history[user_id]\n            if e["error_type"] == error_type and e["timestamp"] > cutoff\n        ]\n        \n        if len(recent_same_errors) >= REPEATED_ERROR_THRESHOLD:\n            return await self._create_alert(\n                user_id=user_id,\n                trigger=StruggleTrigger.REPEATED_ERROR,\n                topic=topic,\n                exercise_id=exercise_id,\n                details={\n                    "error_type": error_type,\n                    "occurrence_count": len(recent_same_errors),\n                },\n                severity=3,\n            )\n        \n        return None\n    \n    async def check_time_on_exercise(\n        self,\n        user_id: str,\n        exercise_id: str,\n        topic: str,\n    ) -> Optional[StruggleAlert]:\n        """\n        Check if student is stuck on an exercise too long.\n        \n        Triggers if >10 minutes on same exercise.\n        """\n        key = f"{user_id}:{exercise_id}"\n        \n        if key not in self._exercise_start_times:\n            self._exercise_start_times[key] = datetime.utcnow()\n            return None\n        \n        start_time = self._exercise_start_times[key]\n        elapsed = datetime.utcnow() - start_time\n        \n        if elapsed > timedelta(minutes=STUCK_TIME_MINUTES):\n            # Only alert once per exercise\n            alert_key = f"stuck:{key}"\n            if alert_key not in self._recent_alerts:\n                self._recent_alerts[alert_key] = datetime.utcnow()\n                return await self._create_alert(\n                    user_id=user_id,\n                    trigger=StruggleTrigger.STUCK_TOO_LONG,\n                    topic=topic,\n                    exercise_id=exercise_id,\n                    details={\n                        "elapsed_minutes": int(elapsed.total_seconds() / 60),\n                    },\n                    severity=2,\n                )\n        \n        return None\n    \n    async def check_quiz_score(\n        self,\n        user_id: str,\n        score: float,\n        topic: str,\n        quiz_id: Optional[str] = None,\n    ) -> Optional[StruggleAlert]:\n        """\n        Check for low quiz score.\n        \n        Triggers if score <50%. \n        """\n        if score < LOW_QUIZ_THRESHOLD:\n            return await self._create_alert(\n                user_id=user_id,\n                trigger=StruggleTrigger.LOW_QUIZ_SCORE,\n                topic=topic,\n                details={\n                    "score": score,\n                    "threshold": LOW_QUIZ_THRESHOLD,\n                    "quiz_id": quiz_id,\n                },\n                severity=2,\n            )\n        \n        return None\n    \n    async def check_message(\n        self,\n        user_id: str,\n        message: str,\n        topic: Optional[str] = None,\n    ) -> Optional[StruggleAlert]:\n        """\n        Check for explicit struggle statements.\n        \n        Triggers if message contains phrases like \"I don't understand\".\n        """\n        message_lower = message.lower()\n        \n        for phrase in STRUGGLE_PHRASES:\n            if phrase in message_lower:\n                return await self._create_alert(\n                    user_id=user_id,\n                    trigger=StruggleTrigger.EXPLICIT_STATEMENT,\n                    topic=topic or "general",\n                    details={\n                        "detected_phrase": phrase,\n                        "message_preview": message[:100],\n                    },\n                    severity=4,  # Higher severity for explicit statements\n                )\n        \n        return None\n    \n    async def check_execution_failure(\n        self,\n        user_id: str,\n        topic: str,\n        exercise_id: Optional[str] = None,\n        error_message: Optional[str] = None,\n    ) -> Optional[StruggleAlert]:\n        """\n        Check for repeated execution failures.\n        \n        Triggers if 5+ failed executions in a row.\n        """\n        key = f"{user_id}:{exercise_id or 'general'}"\n        self._execution_failures[key] += 1\n        \n        if self._execution_failures[key] >= FAILED_EXECUTION_THRESHOLD:\n            # Reset counter after alert\n            failure_count = self._execution_failures[key]\n            self._execution_failures[key] = 0\n            \n            return await self._create_alert(\n                user_id=user_id,\n                trigger=StruggleTrigger.FAILED_EXECUTIONS,\n                topic=topic,\n                exercise_id=exercise_id,\n                details={\n                    "failure_count": failure_count,\n                    "last_error": error_message[:200] if error_message else None,\n                },\n                severity=3,\n            )\n        \n        return None\n    \n    def reset_execution_failures(self, user_id: str, exercise_id: Optional[str] = None):\n        """Reset failure counter on successful execution."""\n        key = f"{user_id}:{exercise_id or 'general'}"\n        self._execution_failures[key] = 0\n    \n    def complete_exercise(self, user_id: str, exercise_id: str):\n        """Mark exercise as complete, clearing tracking data."""\n        key = f"{user_id}:{exercise_id}"\n        \n        # Clear start time\n        if key in self._exercise_start_times:\n            del self._exercise_start_times[key]\n        \n        # Clear failure counter\n        if key in self._execution_failures:\n            del self._execution_failures[key]\n    \n    async def _create_alert(\n        self,\n        user_id: str,\n        trigger: StruggleTrigger,\n        topic: str,\n        exercise_id: Optional[str] = None,\n        details: dict = None,\n        severity: int = 3,\n    ) -> StruggleAlert:\n        """Create and publish a struggle alert."""\n        # Check for recent duplicate alerts (within 5 minutes)\n        alert_key = f"{user_id}:{trigger.value}:{topic}"\n        if alert_key in self._recent_alerts:\n            last_alert = self._recent_alerts[alert_key]\n            if datetime.utcnow() - last_alert < timedelta(minutes=5):\n                logger.debug("skipping_duplicate_alert", user_id=user_id, trigger=trigger.value)\n                return None\n        \n        # Create alert\n        alert = StruggleAlert(\n            id=str(uuid4()),\n            user_id=user_id,\n            trigger=trigger,\n            topic=topic,\n            exercise_id=exercise_id,\n            details=details or {},\n            severity=severity,\n        )\n        \n        # Track alert time\n        self._recent_alerts[alert_key] = datetime.utcnow()\n        \n        # Publish to Kafka (within 30 seconds requirement)\n        await self._publish_alert(alert)\n        \n        logger.info(\n            "struggle_alert_created",\n            user_id=user_id,\n            trigger=trigger.value,\n            topic=topic,\n            severity=severity,\n        )\n        \n        return alert\n    \n    async def _publish_alert(self, alert: StruggleAlert) -> None:\n        """Publish alert to Kafka via Dapr."""\n        try:\n            await self.dapr.publish_event(\n                topic=settings.kafka_topic_struggle,\n                data={\n                    "event_type": "struggle_detected",\n                    "alert_id": alert.id,\n                    "user_id": alert.user_id,\n                    "trigger": alert.trigger.value,\n                    "topic": alert.topic,\n                    "exercise_id": alert.exercise_id,\n                    "details": alert.details,\n                    "severity": alert.severity,\n                    "created_at": alert.created_at.isoformat(),\n                },\n            )\n            logger.info("struggle_alert_published", alert_id=alert.id)\n        except Exception as e:\n            logger.exception("failed_to_publish_alert", error=str(e))\n    \n    async def get_active_alerts(self, user_id: str) -> list[dict]:\n        """Get active (unresolved) alerts for a user."""\n        # In production, this would query the database\n        # For now, return recent alerts from memory\n        alerts = []\n        cutoff = datetime.utcnow() - timedelta(hours=24)\n        \n        for key, timestamp in self._recent_alerts.items():\n            if key.startswith(f"{user_id}:") and timestamp > cutoff:\n                parts = key.split(":")\n                if len(parts) >= 3:\n                    alerts.append({\n                        "trigger": parts[1],\n                        "topic": parts[2],\n                        "timestamp": timestamp.isoformat(),\n                    })\n        \n        return alerts\n\n\n# Global instance\n_detector: Optional[StruggleDetector] = None\n\n\ndef get_struggle_detector() -> StruggleDetector:\n    """Get or create the global struggle detector instance."""\n    global _detector\n    if _detector is None:\n        _detector = StruggleDetector()\n    return _detector\n",
}

def main():
    print("Generating shared backend utilities...")
    
    shared_dir = Path("backend/shared")
    shared_dir.mkdir(parents=True, exist_ok=True)
    
    for filename, content in SHARED_FILES.items():
        file_path = shared_dir / filename
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)
        print(f" Generated {file_path}")
    
    print(" Shared utilities generation complete.")

if __name__ == "__main__":
    main()
